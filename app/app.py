# File: app/app.py

import streamlit as st
import os
import re # <<< THÃŠM VÃ€O
from pathlib import Path
from streamlit_mermaid import st_mermaid
import uuid

# --- IMPORT CÃC THÃ€NH PHáº¦N Tá»ª PIPELINE Má»šI ---
import sys
sys.path.append(str(Path(__file__).parent.parent))
from src.pipeline.prediction_pipeline import create_conversational_chain, get_answer

# --- Cáº¤U HÃŒNH GIAO DIá»†N STREAMLIT ---
st.set_page_config(
    page_title="Pattern-pedia AI",
    page_icon="ğŸ¤–",
    layout="wide"
)

st.title("ğŸ¤– Pattern-pedia AI: Trá»£ lÃ½ CÃ´ng nghá»‡ Pháº§n má»m")
st.markdown("ChÃ o má»«ng báº¡n! HÃ£y Ä‘áº·t má»™t cÃ¢u há»i vá» cÃ¡c chá»§ Ä‘á» nhÆ° Design Patterns, SOLID, Agile, Software Architectures...")

# --- CACHING: Táº¢I MODEL Má»˜T Láº¦N DUY NHáº¤T ---
@st.cache_resource
def load_chain():
    try:
        chain = create_conversational_chain()
        return chain
    except Exception as e:
        st.error(f"Lá»—i khi khá»Ÿi táº¡o AI pipeline: {e}")
        st.error("Vui lÃ²ng kiá»ƒm tra láº¡i Ä‘Æ°á»ng dáº«n tá»›i model LLM vÃ  cháº¯c cháº¯n ráº±ng báº¡n Ä‘Ã£ táº£i model vá».")
        return None

with st.spinner("Äang khá»Ÿi Ä‘á»™ng AI, vui lÃ²ng chá» má»™t lÃ¡t..."):
    chain = load_chain()

# --- KHá»I Táº O SESSION STATE ---
# Äá»•i tÃªn 'messages' thÃ nh 'chat_history' Ä‘á»ƒ nháº¥t quÃ¡n hÆ¡n
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# --- HÃ€M HELPER Äá»‚ HIá»‚N THá»Š CÃ‚U TRáº¢ Lá»œI Cá»¦A AI ---
# TÃ¡ch logic hiá»ƒn thá»‹ ra má»™t hÃ m riÃªng Ä‘á»ƒ code gá»n gÃ ng hÆ¡n
def display_assistant_message(message_content, sources_text, message_index):
    
    # <<< LOGIC Má»šI Báº®T Äáº¦U Tá»ª ÄÃ‚Y >>>
    # Æ¯u tiÃªn tÃ¬m vÃ  váº½ sÆ¡ Ä‘á»“ Mermaid trÆ°á»›c
    mermaid_pattern = re.compile(r"```mermaid(.*?)```", re.DOTALL)
    mermaid_match = mermaid_pattern.search(message_content)

    if mermaid_match:
        # Náº¿u tÃ¬m tháº¥y sÆ¡ Ä‘á»“, tÃ¡ch ná»™i dung ra vÃ  váº½
        before_mermaid = message_content[:mermaid_match.start()]
        mermaid_code = mermaid_match.group(1).strip()
        after_mermaid = message_content[mermaid_match.end():]

        if before_mermaid.strip():
            st.markdown(before_mermaid)
        
        # DÃ¹ng st_mermaid Ä‘á»ƒ Váº¼ sÆ¡ Ä‘á»“
        st_mermaid(mermaid_code, key=f"mermaid_{message_index}_{uuid.uuid4()}")

        with st.expander("Xem mÃ£ Mermaid"):
            st.code(mermaid_code, language='mermaid')
        
        if after_mermaid.strip():
            st.markdown(after_mermaid)
    else:
        # <<< LOGIC CÅ¨ Cá»¦A Báº N Náº°M TRONG ELSE >>>
        # Náº¿u khÃ´ng cÃ³ Mermaid, xá»­ lÃ½ Python vÃ  vÄƒn báº£n nhÆ° bÃ¬nh thÆ°á»ng
        parts = re.split(r"(```python[\s\S]*?```)", message_content)
        for part in parts:
            if part.strip() == "":
                continue
            if part.startswith("```python"):
                code = part.replace("```python", "").replace("```", "").strip()
                st.code(code, language='python')
            else:
                st.markdown(part.strip())

    # Hiá»ƒn thá»‹ nguá»“n tham kháº£o
    if sources_text:
        st.info(sources_text)
        
    # --- CÆ  CHáº¾ FEEDBACK ---
    feedback_key_prefix = f"feedback_{message_index}"
    
    if st.session_state.get(f"{feedback_key_prefix}_submitted") is None:
        col1, col2, _ = st.columns([1, 1, 10])
        with col1:
            if st.button("ğŸ‘", key=f"{feedback_key_prefix}_like"):
                st.session_state[f"{feedback_key_prefix}_submitted"] = "like"
                # TODO: LÆ°u feedback nÃ y vÃ o file log hoáº·c CSDL
                st.rerun()
        with col2:
            if st.button("ğŸ‘", key=f"{feedback_key_prefix}_dislike"):
                st.session_state[f"{feedback_key_prefix}_submitted"] = "dislike"
                # TODO: LÆ°u feedback nÃ y vÃ o file log hoáº·c CSDL
                st.rerun()
    else:
        feedback = st.session_state[f"{feedback_key_prefix}_submitted"]
        if feedback == 'like':
            st.success("Cáº£m Æ¡n báº¡n Ä‘Ã£ thÃ­ch cÃ¢u tráº£ lá»i nÃ y! ğŸ‘")
        elif feedback == 'dislike':
            st.warning("Cáº£m Æ¡n báº¡n Ä‘Ã£ pháº£n há»“i. ChÃºng tÃ´i sáº½ cáº£i thiá»‡n. ğŸ‘")


# --- HIá»‚N THá»Š Lá»ŠCH Sá»¬ Há»˜I THOáº I ---
# DÃ¹ng enumerate Ä‘á»ƒ cÃ³ index cho key cá»§a nÃºt feedback
for i, message in enumerate(st.session_state.chat_history):
    with st.chat_message(message["role"]):
        if message["role"] == "user":
            st.markdown(message["content"])
        else: # role == "assistant"
            display_assistant_message(
                message.get("content", ""),
                message.get("sources", ""),
                i
            )

# --- Xá»¬ LÃ INPUT Cá»¦A NGÆ¯á»œI DÃ™NG ---
if prompt := st.chat_input("CÃ¢u há»i cá»§a báº¡n lÃ  gÃ¬?"):
    if not chain:
        st.warning("Há»‡ thá»‘ng AI chÆ°a sáºµn sÃ ng. Vui lÃ²ng kiá»ƒm tra láº¡i lá»—i á»Ÿ trÃªn.")
    else:
        # ThÃªm tin nháº¯n cá»§a ngÆ°á»i dÃ¹ng vÃ o lá»‹ch sá»­ vÃ  hiá»ƒn thá»‹
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Láº¥y cÃ¢u tráº£ lá»i tá»« AI vÃ  hiá»ƒn thá»‹
        with st.chat_message("assistant"):
            with st.spinner("AI Ä‘ang suy nghÄ©..."):
                response = get_answer(prompt, chain)
                
                answer = response.get('answer', "Xin lá»—i, Ä‘Ã£ cÃ³ lá»—i xáº£y ra.")
                source_documents = response.get('source_documents', [])

                sources_text = ""
                if source_documents:
                    unique_sources = {os.path.basename(doc.metadata.get('source', 'N/A')) for doc in source_documents}
                    if unique_sources:
                        sources_text = "Nguá»“n tham kháº£o: " + ", ".join(sorted(list(unique_sources)))
                
                # Hiá»ƒn thá»‹ cÃ¢u tráº£ lá»i má»›i báº±ng hÃ m helper
                display_assistant_message(answer, sources_text, len(st.session_state.chat_history))
        
        # ThÃªm cÃ¢u tráº£ lá»i cá»§a AI vÃ o lá»‹ch sá»­ Ä‘á»ƒ lÆ°u láº¡i
        st.session_state.chat_history.append({
            "role": "assistant", 
            "content": answer, # Chá»‰ lÆ°u ná»™i dung cÃ¢u tráº£ lá»i
            "sources": sources_text # LÆ°u nguá»“n riÃªng
        })